# AUTOGENERATED! DO NOT EDIT! File to edit: emotion-recognition-notebook.ipynb.

# %% auto 0
__all__ = ['data_path', 'model_path', 'learner', 'image', 'label', 'examples', 'intf', 'search_images', 'classify_image']

# %% emotion-recognition-notebook.ipynb 1
# import
# from bing_image_downloader import downloader
import nbdev

from duckduckgo_search import ddg_images
from fastbook import search_images_ddg
from fastcore.all import *
from fastai.vision.all import *

# %% emotion-recognition-notebook.ipynb 2
#init hydra
from hydra import initialize, compose
from hydra.utils import to_absolute_path as abspath

with initialize(version_base=None, config_path="../configs"):
    config = compose(config_name="main-config.yaml")

data_path = abspath("../" + config.data.path)
model_path = abspath("../" + config.model.path)

# %% emotion-recognition-notebook.ipynb 3
#search item function
def search_images(term, max_images=30):
    print(f"Searching for '{term}'")
    return search_images_ddg(term, max_images=max_images)

# %% emotion-recognition-notebook.ipynb 18
learner = load_learner(model_path + '/emotion.pkl')

# %% emotion-recognition-notebook.ipynb 19
def classify_image(img):
    pred, idx, probs = learner.predict(img)
    return dict(zip(learner.dls.vocab, map(float, probs)))


# %% emotion-recognition-notebook.ipynb 21
import gradio as gr

image = gr.inputs.Image(shape=(192, 192))
label = gr.outputs.Label()
examples = [
    [data_path +'/test/happy.jpg'],
    [data_path +'/test/sad.jpg'],
    [data_path +'/test/angry.jpg'],
    [data_path +'/test/surprised.jpg']
]

intf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)
intf.launch(inline=False)
